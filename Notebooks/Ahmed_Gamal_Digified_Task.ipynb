{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V31nOwp-oe1-"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4le9EejhTzG",
        "outputId": "f6fd59c1-dfdf-4e27-c683-34b138efed27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 16.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 68.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 43.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting arabic-stopwords\n",
            "  Downloading Arabic_Stopwords-0.3-py3-none-any.whl (353 kB)\n",
            "\u001b[K     |████████████████████████████████| 353 kB 30.5 MB/s \n",
            "\u001b[?25hCollecting pyarabic>=0.6.2\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 67.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from pyarabic>=0.6.2->arabic-stopwords) (1.15.0)\n",
            "Installing collected packages: pyarabic, arabic-stopwords\n",
            "Successfully installed arabic-stopwords-0.3 pyarabic-0.6.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[K     |████████████████████████████████| 410 kB 24.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (1.3.5)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (4.6.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->nlpaug) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tashaphyne\n",
            "  Downloading Tashaphyne-0.3.6-py3-none-any.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 24.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarabic in /usr/local/lib/python3.8/dist-packages (from tashaphyne) (0.6.15)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from pyarabic->tashaphyne) (1.15.0)\n",
            "Installing collected packages: tashaphyne\n",
            "Successfully installed tashaphyne-0.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install arabic-stopwords\n",
        "!pip install nlpaug\n",
        "!pip install tashaphyne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISIfYHLgAzMK",
        "outputId": "be6c5db3-7a6c-40a0-cafa-f6ddc6bcf19f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import tensorflow as tf \n",
        "from google.colab import drive\n",
        "import random \n",
        "drive.mount('/content/gdrive')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sb\n",
        "import time \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "# from tashaphyne.stemming import ArabicLightStemmer\n",
        "# from nltk.stem.isri import ISRIStemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLWsZa_CogrR"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKI-V8YgA2GE"
      },
      "outputs": [],
      "source": [
        "path1 = '/content/gdrive/MyDrive/AWS/arabic_names_with_gender.csv'\n",
        "df1 = pd.read_csv(path1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDN2t37JBI1l"
      },
      "outputs": [],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8OhJMpM99Zm"
      },
      "outputs": [],
      "source": [
        "df1.rename(columns = {'gender':'Gender', 'name':'Name'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gYYoG0x-GnY"
      },
      "outputs": [],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8xwBj6qEYLn"
      },
      "outputs": [],
      "source": [
        "df1['Gender'] = df1['Gender'].replace(['انثى'], ['F'])\n",
        "df1['Gender'] = df1['Gender'].replace(['ذكر'], ['M'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfIseo4TEYOU"
      },
      "outputs": [],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suPwYLpu7r38"
      },
      "outputs": [],
      "source": [
        "path2 = '/content/gdrive/MyDrive/AWS/females_ar.csv'\n",
        "df2 = pd.read_csv(path2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7oVF57C76GE"
      },
      "outputs": [],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rOB_0Wz76Ii"
      },
      "outputs": [],
      "source": [
        "path3 = '/content/gdrive/MyDrive/AWS/Arabic_names.csv'\n",
        "df3 = pd.read_csv(path3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keq3VlCC8n9X"
      },
      "outputs": [],
      "source": [
        "df3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30Im133g2__9"
      },
      "outputs": [],
      "source": [
        "fnames = np.genfromtxt('/content/gdrive/MyDrive/AWS/KDBAGIV.txt', delimiter=',', dtype=str, encoding='utf-8')\n",
        "\n",
        "lst = []\n",
        "for i in fnames:\n",
        "  lst.append(i.split('\\t')) \n",
        "lst "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXnmlm987wXO"
      },
      "outputs": [],
      "source": [
        "df4 = pd.DataFrame(lst[2:-1], columns=['a','b','c','d'])\n",
        "df4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaZRh4LU70AS"
      },
      "outputs": [],
      "source": [
        "df4.rename(columns = {'d':'Gender', 'c':'Name'}, inplace = True)\n",
        "df4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvFWeffr70Cl"
      },
      "outputs": [],
      "source": [
        "df4 = df4.loc[:,'Name':]\n",
        "df4.drop_duplicates(inplace=True)\n",
        "df4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFi50l4u3ACj"
      },
      "outputs": [],
      "source": [
        "fnames1 = np.genfromtxt('/content/gdrive/MyDrive/AWS/KDBASN.txt', delimiter=',', dtype=str, encoding='utf-8')\n",
        "\n",
        "\n",
        "lst = []\n",
        "for i in fnames1:\n",
        "  lst.append(i.split('\\t')) \n",
        "\n",
        "lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S22oOhw78ICi"
      },
      "outputs": [],
      "source": [
        "df5 = pd.DataFrame(lst[2:-1], columns=['a','b','c','d','e'])\n",
        "df5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvNrZv3W8IFC"
      },
      "outputs": [],
      "source": [
        "df5.rename(columns = {'d':'Gender', 'c':'Name'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqmowC4d8NRS"
      },
      "outputs": [],
      "source": [
        "df5 = df5.loc[:,'Name':'Gender']\n",
        "df5['Gender'] = 'M'\n",
        "df5.drop_duplicates(inplace=True)\n",
        "df5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm-91CjF9NpQ"
      },
      "outputs": [],
      "source": [
        "fnames1 = np.genfromtxt('/content/gdrive/MyDrive/AWS/KDBCOUNTER.txt', delimiter=',', dtype=str, encoding='utf-8')\n",
        "\n",
        "\n",
        "lst = []\n",
        "for i in fnames1:\n",
        "  lst.append(i.split('\\t')) \n",
        "\n",
        "lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9ru3O1g9SQ6"
      },
      "outputs": [],
      "source": [
        "df6 = pd.DataFrame(lst[2:-1], columns=['a','b','c','d','e','f','g','i','j'])\n",
        "df6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l3CiEaW9SQ7"
      },
      "outputs": [],
      "source": [
        "df6.rename(columns = {'e':'Gender', 'd':'Name'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5eEbrgv9SQ7"
      },
      "outputs": [],
      "source": [
        "df6 = df6.loc[:,'Name':'Gender']\n",
        "df6.drop_duplicates(inplace=True)\n",
        "df6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QxM_jnx9vsH"
      },
      "outputs": [],
      "source": [
        "fnames1 = np.genfromtxt('/content/gdrive/MyDrive/AWS/KDBGIVE.txt', delimiter=',', dtype=str, encoding='utf-8')\n",
        "\n",
        "\n",
        "lst = []\n",
        "for i in fnames1:\n",
        "  lst.append(i.split('\\t')) \n",
        "\n",
        "lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VDYCyOm9vsH"
      },
      "outputs": [],
      "source": [
        "df7 = pd.DataFrame(lst[2:-1], columns=['a','b','c','d','e','f','g','i','j','k','l','m'])\n",
        "df7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRdvhCXb9vsH"
      },
      "outputs": [],
      "source": [
        "df7.rename(columns = {'e':'Gender', 'c':'Name'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lun5WRz9vsI"
      },
      "outputs": [],
      "source": [
        "df7 = df7.loc[:,'Name':'Gender']\n",
        "df7.drop(columns=['d'], inplace=True)\n",
        "df7.drop_duplicates(inplace=True)\n",
        "df7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlKEGLo5-8N2"
      },
      "outputs": [],
      "source": [
        "fnames1 = np.genfromtxt('/content/gdrive/MyDrive/AWS/KDBHETERO.txt', delimiter=',', dtype=str, encoding='utf-8')\n",
        "\n",
        "\n",
        "lst = []\n",
        "for i in fnames1:\n",
        "  lst.append(i.split('\\t')) \n",
        "\n",
        "lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tm2uKDzj-8N3"
      },
      "outputs": [],
      "source": [
        "df8 = pd.DataFrame(lst[2:-1], columns=['a','b','c','d','e','f','g','i','j','k'])\n",
        "df8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayuGdyJF-8N3"
      },
      "outputs": [],
      "source": [
        "df8.rename(columns = {'i':'Gender', 'f':'Name', 'Name':'i','Gender':'f'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa36SvSN-8N3"
      },
      "outputs": [],
      "source": [
        "df8 = df8.loc[:,'Name':'Gender']\n",
        "df8.drop(columns=['g'], inplace=True)\n",
        "df8.drop_duplicates(inplace=True)\n",
        "df8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RC9GMRB_8cJ"
      },
      "outputs": [],
      "source": [
        "fnames1 = np.genfromtxt('/content/gdrive/MyDrive/AWS/KDBTRANSAR.txt', delimiter=',', dtype=str, encoding='utf-8')\n",
        "\n",
        "\n",
        "lst = []\n",
        "for i in fnames1:\n",
        "  lst.append(i.split('\\t')) \n",
        "\n",
        "lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzksgRR0_8cJ"
      },
      "outputs": [],
      "source": [
        "df9 = pd.DataFrame(lst[2:-1], columns=['a','b','c','d','e','f'])\n",
        "df9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwEdWZno_8cK"
      },
      "outputs": [],
      "source": [
        "df9.rename(columns = {'e':'Gender', 'b':'Name'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Db3B_nIw_8cK"
      },
      "outputs": [],
      "source": [
        "df9 = df9.loc[:,'Name':'Gender']\n",
        "df9.drop(columns=['c','d'], inplace=True)\n",
        "df9.drop_duplicates(inplace=True)\n",
        "df9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjk3jhTTAvnS"
      },
      "outputs": [],
      "source": [
        "fnames1 = np.genfromtxt('/content/gdrive/MyDrive/AWS/KDBUNIQ.txt', delimiter=',', dtype=str, encoding='utf-8')\n",
        "\n",
        "\n",
        "lst = []\n",
        "for i in fnames1:\n",
        "  lst.append(i.split('\\t')) \n",
        "\n",
        "lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKoPnY9JAvnT"
      },
      "outputs": [],
      "source": [
        "df10 = pd.DataFrame(lst[2:-1], columns=['a','b','c','d','e','f','g'])\n",
        "df10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCss1uXqAvnT"
      },
      "outputs": [],
      "source": [
        "df10.rename(columns = {'d':'Gender', 'b':'Name'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsRN70vwAvnT"
      },
      "outputs": [],
      "source": [
        "df10 = df10.loc[:,'Name':'Gender']\n",
        "df10.drop(columns=['c'], inplace=True)\n",
        "df10.drop_duplicates(inplace=True)\n",
        "df10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62GwLtvIBRfa"
      },
      "outputs": [],
      "source": [
        "fnames1 = np.genfromtxt('/content/gdrive/MyDrive/AWS/KDBVAROM.txt', delimiter=',', dtype=str, encoding='utf-8')\n",
        "\n",
        "\n",
        "lst = []\n",
        "for i in fnames1:\n",
        "  lst.append(i.split('\\t')) \n",
        "\n",
        "lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oa7AN6nBRfb"
      },
      "outputs": [],
      "source": [
        "df11 = pd.DataFrame(lst[2:-1], columns=['a','b','c'])\n",
        "df11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nb_y5WNpBRfb"
      },
      "outputs": [],
      "source": [
        "df11.rename(columns = {'b':'Gender', 'c':'Name'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjfmriRlBRfb"
      },
      "outputs": [],
      "source": [
        "df11 = df11.loc[:,'Gender':]\n",
        "# df11.drop(columns=['c'], inplace=True)\n",
        "df11['Gender'] = 'M'\n",
        "df11.drop_duplicates(inplace=True)\n",
        "df11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drmknWr1BxGP"
      },
      "outputs": [],
      "source": [
        "fnames1 = np.genfromtxt('/content/gdrive/MyDrive/AWS/KDBWNAN.txt', delimiter=',', dtype=str, encoding='utf-8')\n",
        "\n",
        "\n",
        "lst = []\n",
        "for i in fnames1:\n",
        "  lst.append(i.split('\\t')) \n",
        "\n",
        "lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8IizkrSBxGP"
      },
      "outputs": [],
      "source": [
        "df12 = pd.DataFrame(lst[2:-1], columns=['a','b','c','d','e', 'f', 'g','i','k','l','m','n','o','p','q','r','s'])\n",
        "df12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8ovuHPdBxGQ"
      },
      "outputs": [],
      "source": [
        "df12.rename(columns = {'c':'Gender', 'o':'Name'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2KdQhEyBxGQ"
      },
      "outputs": [],
      "source": [
        "df12 = df12.loc[:,'Gender':'Name']\n",
        "df12.drop(columns=['d','e', 'f', 'g','i','k','l','m','n'], inplace=True)\n",
        "df12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZHJ6YhH8xE-"
      },
      "outputs": [],
      "source": [
        "frames = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12]\n",
        "\n",
        "df_full = pd.concat(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjfMUXFcWSla"
      },
      "outputs": [],
      "source": [
        "df_full.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OG4jO512HOPG"
      },
      "outputs": [],
      "source": [
        "df_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deN4quoYHtIJ"
      },
      "outputs": [],
      "source": [
        "df_full.drop_duplicates(inplace=True)\n",
        "df_full['Gender'] = df_full['Gender'].replace(['Female'], ['F'])\n",
        "df_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPC77uITH0ZW"
      },
      "outputs": [],
      "source": [
        "df_full.to_csv('/content/gdrive/MyDrive/AWS/Names.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRL0BRen7IX4"
      },
      "outputs": [],
      "source": [
        "df_full['Name'] = df_full['Name'].astype('str') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wre2K6ib6FM-"
      },
      "outputs": [],
      "source": [
        "mnames = df_full[df_full['Gender'] == \"M\"]['Name']\n",
        "mnames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SwVCjHQ6FPV"
      },
      "outputs": [],
      "source": [
        "fnames = df_full[df_full['Gender'] == \"F\"]['Name']\n",
        "fnames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLP0mabm5uYw"
      },
      "source": [
        "Generating Real Names "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9uy2KYxw4YC"
      },
      "outputs": [],
      "source": [
        "full_names = []\n",
        "\n",
        "for name in mnames:\n",
        " # print(name)\n",
        "  full_name = name + ' ' + np.random.choice(mnames, 100, replace=False)\n",
        "  full_name = full_name + ' ' + np.random.choice(mnames, 100, replace=False)\n",
        "  # print(full_name)\n",
        "  full_names.extend(full_name)\n",
        "\n",
        "\n",
        "for name in fnames:\n",
        " # print(name)\n",
        "  full_name = name + ' ' + np.random.choice(mnames, 100, replace=False)\n",
        "  full_name = full_name + ' ' + np.random.choice(mnames, 100, replace=False)\n",
        "  # print(full_name)\n",
        "  full_names.extend(full_name)\n",
        "\n",
        "# print(full_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhXeKDbV5uDi"
      },
      "outputs": [],
      "source": [
        "len(full_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UJrMK5u5uIn"
      },
      "outputs": [],
      "source": [
        "df_real = pd.DataFrame({'Name':full_names , 'Valid': 1})\n",
        "df_real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhJ1ul1h5uLc"
      },
      "outputs": [],
      "source": [
        "df_real.drop_duplicates(inplace=True)\n",
        "df_real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-wlvjc19qWi"
      },
      "outputs": [],
      "source": [
        "df_real = df_real.sample(frac=1)\n",
        "df_real"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf8INE-P5q3D"
      },
      "source": [
        "Generating Fake Names "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ap5dhAp5uN_"
      },
      "outputs": [],
      "source": [
        "letter_dict=['ا','ب','ت','ث','ج','ح','خ','د','ذ','ر','ز','س','ش','ص','ض','ط','ظ','ع','غ','ف','ق','ك','ل','م','ن','ه','و','ؤ','ي','ء','ئ','-','أ','ة','،','.','ى']\n",
        "\n",
        "incorrect_names = []\n",
        "for i in range(len(df_real)):\n",
        "  full_name = ''.join(random.sample(letter_dict, random.randint(4,6))) + ' '\n",
        "  full_name = full_name + ''.join(random.sample(letter_dict, random.randint(4,6))) + ' '\n",
        "  full_name = full_name + ''.join(random.sample(letter_dict, random.randint(4,6)))\n",
        "  incorrect_names.append(full_name)\n",
        "\n",
        "print(len(incorrect_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ItIVlZj-RFw"
      },
      "outputs": [],
      "source": [
        "df_fake = pd.DataFrame({'Name':incorrect_names , 'Valid': 0})\n",
        "df_fake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHtDvP55-RR8"
      },
      "outputs": [],
      "source": [
        "frames = [df_real, df_fake]\n",
        "\n",
        "df_full = pd.concat(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Q7qECZr-RUu"
      },
      "outputs": [],
      "source": [
        "df_full.drop_duplicates(inplace=True)\n",
        "df_full = df_full.sample(frac=1)\n",
        "df_full"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Taieuved-SBN"
      },
      "source": [
        "Save the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmcSsx9XPs86"
      },
      "outputs": [],
      "source": [
        "df_full.to_csv('/content/gdrive/MyDrive/AWS/Full_Names.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOCDcSt4oV0I"
      },
      "source": [
        "## Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9USjf_0gE6mz"
      },
      "outputs": [],
      "source": [
        "df_full"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tashaphyne.stemming import ArabicLightStemmer"
      ],
      "metadata": {
        "id": "MEIt9_tqMNhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNXTypRijpa3"
      },
      "outputs": [],
      "source": [
        "ArListem = ArabicLightStemmer()\n",
        "\n",
        "def stem(text):\n",
        "    zen = TextBlob(text)\n",
        "    words = zen.words\n",
        "    cleaned = list()\n",
        "    for w in words:\n",
        "        ArListem.light_stem(w)\n",
        "        cleaned.append(ArListem.get_root())\n",
        "    return \" \".join(cleaned)\n",
        "\n",
        "import pyarabic.araby as araby\n",
        "def normalizeArabic(text):\n",
        "    text = text.strip()\n",
        "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ؤ\", \"ء\", text)\n",
        "    text = re.sub(\"ئ\", \"ء\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    noise = re.compile(\"\"\" ّ    | # Tashdid\n",
        "                             َ    | # Fatha\n",
        "                             ً    | # Tanwin Fath\n",
        "                             ُ    | # Damma\n",
        "                             ٌ    | # Tanwin Damm\n",
        "                             ِ    | # Kasra\n",
        "                             ٍ    | # Tanwin Kasr\n",
        "                             ْ    | # Sukun\n",
        "                             ـ     # Tatwil/Kashida\n",
        "                         \"\"\", re.VERBOSE)\n",
        "    text = re.sub(noise, '', text)\n",
        "    text = re.sub(r'(.)\\1+', r\"\\1\\1\", text) # Remove longation\n",
        "    return araby.strip_tashkeel(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjrZoEqrsYaB"
      },
      "outputs": [],
      "source": [
        "def clean_tweet(text):\n",
        "    text = re.sub('#\\d+K\\d+', ' ', text)  # years like 2K19\n",
        "    text = re.sub('http\\S+\\s*', ' ', text)  # remove URLs\n",
        "    text = re.sub('RT|cc', ' ', text)  # remove RT and cc\n",
        "    text = re.sub('@[^\\s]+',' ',text)\n",
        "    text = clean_hashtag(text)\n",
        "    text = clean_emoji(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSTIVpz0sYcz"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    ## Remove punctuations\n",
        "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)  # remove punctuation\n",
        "    ## remove extra whitespace\n",
        "    text = re.sub('\\s+', ' ', text)  \n",
        "    ## Convert text to lowercases\n",
        "    text = text.lower()\n",
        "    ## Remove numbers\n",
        "    text = re.sub(\"\\d+\", \" \", text)\n",
        "    ## Remove Tashkeel\n",
        "    text = normalizeArabic(text)\n",
        "    #text = re.sub('\\W+', ' ', text)\n",
        "    text = re.sub('[A-Za-z]+',' ',text)\n",
        "    text = re.sub(r'\\\\u[A-Za-z0-9\\\\]+',' ',text)\n",
        "    ## remove extra whitespace\n",
        "    text = re.sub('\\s+', ' ', text)  \n",
        "    #Stemming\n",
        "    text = stem(text)\n",
        "    return text\n",
        "\n",
        "# train = df_full['Name'].apply(lambda x:clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qppQDuQG4pek"
      },
      "outputs": [],
      "source": [
        "df_full['clean_data'] = train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfVT0tiIGrVy"
      },
      "outputs": [],
      "source": [
        "df_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A47sAVHsF9a-"
      },
      "outputs": [],
      "source": [
        "df_full.to_csv('/content/gdrive/MyDrive/AWS/Full_Names_Clean.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_full = pd.read_csv('/content/gdrive/MyDrive/AWS/Full_Names_Clean.csv')"
      ],
      "metadata": {
        "id": "2_qJvft2fv-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "p9bl_sozc0ch",
        "outputId": "27a896ec-ed70-4b48-f959-fe7eba57ad20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Name  Valid       clean_data\n",
              "0        وؤئهك ذيزحر بصزهن      0     ءءه ذزحر صزز\n",
              "1          صلا شبلى مريانس      1      صلل شبل رنس\n",
              "2         مدتس هؤ.صز يقلأح      0  دتس هءء صزز قلح\n",
              "3         أةفذ ىأئاذ احأؤى      0      هفذ ءوذ وحء\n",
              "4        ىك.فنغ شثنهئ لقوه      0  ك نغغ شثنهء قوه\n",
              "...                    ...    ...              ...\n",
              "2261595   ظغءر فثأق. كثءظح      0    ظغءر فثق ثءظح\n",
              "2261596   سميح اسكاروس رسم      1     سمح سكرس رسم\n",
              "2261597   تحز، خعسء غؤعتوق      0   حزز خعسء غءعتق\n",
              "2261598  ضؤثف ظضوءئ شا،-ي.      0    ضءثف ظضءء ش ي\n",
              "2261599  سلومه حناوى زاهِد      1      لوم حنو زهد\n",
              "\n",
              "[2261600 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecd05e95-b2a5-497f-9b27-81d920873a62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Valid</th>\n",
              "      <th>clean_data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>وؤئهك ذيزحر بصزهن</td>\n",
              "      <td>0</td>\n",
              "      <td>ءءه ذزحر صزز</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>صلا شبلى مريانس</td>\n",
              "      <td>1</td>\n",
              "      <td>صلل شبل رنس</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>مدتس هؤ.صز يقلأح</td>\n",
              "      <td>0</td>\n",
              "      <td>دتس هءء صزز قلح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>أةفذ ىأئاذ احأؤى</td>\n",
              "      <td>0</td>\n",
              "      <td>هفذ ءوذ وحء</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ىك.فنغ شثنهئ لقوه</td>\n",
              "      <td>0</td>\n",
              "      <td>ك نغغ شثنهء قوه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261595</th>\n",
              "      <td>ظغءر فثأق. كثءظح</td>\n",
              "      <td>0</td>\n",
              "      <td>ظغءر فثق ثءظح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261596</th>\n",
              "      <td>سميح اسكاروس رسم</td>\n",
              "      <td>1</td>\n",
              "      <td>سمح سكرس رسم</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261597</th>\n",
              "      <td>تحز، خعسء غؤعتوق</td>\n",
              "      <td>0</td>\n",
              "      <td>حزز خعسء غءعتق</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261598</th>\n",
              "      <td>ضؤثف ظضوءئ شا،-ي.</td>\n",
              "      <td>0</td>\n",
              "      <td>ضءثف ظضءء ش ي</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261599</th>\n",
              "      <td>سلومه حناوى زاهِد</td>\n",
              "      <td>1</td>\n",
              "      <td>لوم حنو زهد</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2261600 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecd05e95-b2a5-497f-9b27-81d920873a62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecd05e95-b2a5-497f-9b27-81d920873a62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecd05e95-b2a5-497f-9b27-81d920873a62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvwSQ8hucsXS",
        "outputId": "e0992ad2-2d78-46ec-905d-686c5913ded6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          وؤئهك ذيزحر بصزهن\n",
              "1            صلا شبلى مريانس\n",
              "2           مدتس هؤ.صز يقلأح\n",
              "3           أةفذ ىأئاذ احأؤى\n",
              "4          ىك.فنغ شثنهئ لقوه\n",
              "                 ...        \n",
              "2261595     ظغءر فثأق. كثءظح\n",
              "2261596     سميح اسكاروس رسم\n",
              "2261597     تحز، خعسء غؤعتوق\n",
              "2261598    ضؤثف ظضوءئ شا،-ي.\n",
              "2261599    سلومه حناوى زاهِد\n",
              "Name: Name, Length: 2261600, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "seq = df_full['Name']\n",
        "seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NuRNioKodsQ"
      },
      "source": [
        "## **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Zvp9NScfMnw"
      },
      "outputs": [],
      "source": [
        "dataset = df_full\n",
        "# Separate out the sentences and labels into training and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(dataset['clean_data'], dataset['Valid'], test_size=0.3,random_state=42, stratify=dataset['Valid'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jhhtKF7-_dp",
        "outputId": "86c5a889-6ff1-46d8-b501-d08b35ddd7b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "max_length = max([len(i) for i in x_train])\n",
        "max_length"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 38"
      ],
      "metadata": {
        "id": "AC0f9s0QMZ-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78icewYRgfxh"
      },
      "outputs": [],
      "source": [
        "vocab_size = 800\n",
        "embedding_dim = 100\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"UNK\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(x_train)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, \n",
        "                       truncating=trunc_type)\n",
        "\n",
        "\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(x_test)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, \n",
        "                               padding=padding_type, truncating=trunc_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBMgzp-_lMTp",
        "outputId": "78e4f313-ff2b-42fd-ffc4-9e06b96ae53c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 38, 100)           80000     \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 64)               25728     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 105,793\n",
            "Trainable params: 105,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_gru = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "learning_rate = 0.00003 # slower than the default learning rate\n",
        "model_gru.compile(loss='binary_crossentropy',\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "model_gru.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh4JMpk_opQl"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfl1W-zVldpn",
        "outputId": "5a55aafa-d060-4de5-e73d-10d7abd67445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "49473/49473 [==============================] - 441s 9ms/step - loss: 0.2048 - accuracy: 0.9251 - val_loss: 0.1851 - val_accuracy: 0.9313\n",
            "Epoch 2/5\n",
            "49473/49473 [==============================] - 435s 9ms/step - loss: 0.1846 - accuracy: 0.9314 - val_loss: 0.1853 - val_accuracy: 0.9312\n",
            "Epoch 3/5\n",
            "49473/49473 [==============================] - 432s 9ms/step - loss: 0.1837 - accuracy: 0.9316 - val_loss: 0.1838 - val_accuracy: 0.9315\n",
            "Epoch 4/5\n",
            "49473/49473 [==============================] - 433s 9ms/step - loss: 0.1831 - accuracy: 0.9317 - val_loss: 0.1840 - val_accuracy: 0.9315\n",
            "Epoch 5/5\n",
            "49473/49473 [==============================] - 429s 9ms/step - loss: 0.1828 - accuracy: 0.9318 - val_loss: 0.1840 - val_accuracy: 0.9317\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f50a4473340>"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "model_gru.fit(training_padded, y_train, epochs=num_epochs, validation_data=(testing_padded, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3bAySDFos74"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXJFjjtQWaNl"
      },
      "outputs": [],
      "source": [
        "# Use the model to predict a review   \n",
        "Name1 = ['أحمد جمال أحمد']\n",
        "Name2 = ['باسم وحيد السيد']\n",
        "Name3 = ['باسمم وحةد السد']\n",
        "Name4 = ['باس ود الس']\n",
        "Name5 = ['سبم وح السيد']\n",
        "Name6 = ['باسم يبلي سيلبس']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFf6C1eoJf8v",
        "outputId": "a70f1ab5-8770-4fea-f61a-747451f664cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['أحمد جمال أحمد']\n",
            "['حمد جمل حمد']\n",
            "[[28, 165, 28]]\n",
            "[[ 28 165  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "['أحمد جمال أحمد']\n",
            "Confidence Score :0.9999305009841919\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# df_test = pd.DataFrame(Names)\n",
        "testing = []\n",
        "print(Name1) \n",
        "\n",
        "# preprocess the sequences\n",
        "testing.append(clean_text(Name1[0]))\n",
        "\n",
        "# Create the sequences\n",
        "padding_type='post'\n",
        "print(testing)\n",
        "sample_sequences = tokenizer.texts_to_sequences(testing)\n",
        "print(sample_sequences)\n",
        "fakes_padded = pad_sequences(sample_sequences, padding=padding_type, maxlen=max_length)                      \n",
        "print(fakes_padded)\n",
        "classes = model_gru.predict(fakes_padded)\n",
        "\n",
        "# The closer the class is to 1, the more positive the review is deemed to be\n",
        "print(Name1)\n",
        "print(f'Confidence Score :{classes[0][0]}')\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhhm5PrrWV_a",
        "outputId": "c8eb763c-5d9c-435f-ac9b-9c6f9ef1cb1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['باسم وحيد السيد']\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "['باسم وحيد السيد']\n",
            "Confidence Score :0.9991043210029602\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# df_test = pd.DataFrame(Names)\n",
        "testing = []\n",
        "print(Name2) \n",
        "\n",
        "# preprocess the sequences\n",
        "testing.append(clean_text(Name2[0]))\n",
        "\n",
        "# Create the sequences\n",
        "padding_type='post'\n",
        "sample_sequences = tokenizer.texts_to_sequences(testing)\n",
        "fakes_padded = pad_sequences(sample_sequences, padding=padding_type, maxlen=max_length)                      \n",
        "\n",
        "classes = model_gru.predict(fakes_padded)\n",
        "\n",
        "# The closer the class is to 1, the more positive the review is deemed to be\n",
        "print(Name2)\n",
        "print(f'Confidence Score :{classes[0][0]}')\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8LWbt_IWWBt",
        "outputId": "31afd0b1-7e28-491a-80c3-f92c8a2d341e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['باسمم وحةد السد']\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "['باسمم وحةد السد']\n",
            "Confidence Score :0.9966051578521729\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# df_test = pd.DataFrame(Names)\n",
        "testing = []\n",
        "print(Name3) \n",
        "\n",
        "# preprocess the sequences\n",
        "testing.append(clean_text(Name3[0]))\n",
        "\n",
        "# Create the sequences\n",
        "padding_type='post'\n",
        "sample_sequences = tokenizer.texts_to_sequences(testing)\n",
        "fakes_padded = pad_sequences(sample_sequences, padding=padding_type, maxlen=max_length)                      \n",
        "\n",
        "classes = model_gru.predict(fakes_padded)\n",
        "\n",
        "# The closer the class is to 1, the more positive the review is deemed to be\n",
        "print(Name3)\n",
        "print(f'Confidence Score :{classes[0][0]}')\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujMMJfDSWWEN",
        "outputId": "cde90e16-fc5d-42a1-8fd2-aaf7e7096451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['باس ود الس']\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "['باس ود الس']\n",
            "Confidence Score :0.16175003349781036\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# df_test = pd.DataFrame(Names)\n",
        "testing = []\n",
        "print(Name4) \n",
        "\n",
        "# preprocess the sequences\n",
        "testing.append(clean_text(Name4[0]))\n",
        "\n",
        "# Create the sequences\n",
        "padding_type='post'\n",
        "sample_sequences = tokenizer.texts_to_sequences(testing)\n",
        "fakes_padded = pad_sequences(sample_sequences, padding=padding_type, maxlen=max_length)                      \n",
        "\n",
        "classes = model_gru.predict(fakes_padded)\n",
        "\n",
        "# The closer the class is to 1, the more positive the review is deemed to be\n",
        "print(Name4)\n",
        "print(f'Confidence Score :{classes[0][0]}')\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bufYZC_uWWIc",
        "outputId": "dbae4e37-93a9-4d4b-ff55-71798c9e31e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['سبم وح السيد']\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "['سبم وح السيد']\n",
            "Confidence Score :0.9389397501945496\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# df_test = pd.DataFrame(Names)\n",
        "testing = []\n",
        "print(Name5) \n",
        "\n",
        "# preprocess the sequences\n",
        "testing.append(clean_text(Name5[0]))\n",
        "\n",
        "# Create the sequences\n",
        "padding_type='post'\n",
        "sample_sequences = tokenizer.texts_to_sequences(testing)\n",
        "fakes_padded = pad_sequences(sample_sequences, padding=padding_type, maxlen=max_length)                      \n",
        "\n",
        "classes = model_gru.predict(fakes_padded)\n",
        "\n",
        "# The closer the class is to 1, the more positive the review is deemed to be\n",
        "print(Name5)\n",
        "print(f'Confidence Score :{classes[0][0]}')\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t210GGEYWpuy",
        "outputId": "0dc8a0c1-7ecd-4f02-f39b-ccb9d7df60c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['باسم يبلي سيلبس']\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "['باسم يبلي سيلبس']\n",
            "Confidence Score :0.9988861680030823\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# df_test = pd.DataFrame(Names)\n",
        "testing = []\n",
        "print(Name6) \n",
        "\n",
        "# preprocess the sequences\n",
        "testing.append(clean_text(Name6[0]))\n",
        "\n",
        "# Create the sequences\n",
        "padding_type='post'\n",
        "sample_sequences = tokenizer.texts_to_sequences(testing)\n",
        "fakes_padded = pad_sequences(sample_sequences, padding=padding_type, maxlen=max_length)                      \n",
        "\n",
        "classes = model_gru.predict(fakes_padded)\n",
        "\n",
        "# The closer the class is to 1, the more positive the review is deemed to be\n",
        "print(Name6)\n",
        "print(f'Confidence Score :{classes[0][0]}')\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo2K-pfzPSOo"
      },
      "source": [
        "## **Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwbYc5bhPU-1",
        "outputId": "c949fcc0-19b9-4f43-f91d-f12118c3ba74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/AWS/1670681640.h5\n"
          ]
        }
      ],
      "source": [
        "t = time.time()\n",
        "\n",
        "export_path_keras = \"/content/gdrive/MyDrive/AWS/{}.h5\".format(int(t))\n",
        "print(export_path_keras)\n",
        "\n",
        "model_gru.save(export_path_keras)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer = joblib.load('/content/gdrive/MyDrive/AWS/tokenizer.joblib')\n",
        "# model_gru = tf.keras.models.load_model('/content/gdrive/MyDrive/AWS/1670681640.h5')"
      ],
      "metadata": {
        "id": "WjZcBGPwK8TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# # saving\n",
        "# with open('/content/gdrive/MyDrive/AWS/tokenizer.pickle', 'wb') as handle:\n",
        "#     pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# # loading\n",
        "# with open('tokenizer.pickle', 'rb') as handle:\n",
        "#     tokenizer = pickle.load(handle)"
      ],
      "metadata": {
        "id": "kYQfzgzRff2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib "
      ],
      "metadata": {
        "id": "1JhYFysOgcE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(tokenizer, '/content/gdrive/MyDrive/AWS/tokenizer.joblib', compress=9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_ITvTnYCuKi",
        "outputId": "b34883b0-3bd7-4733-9d79-9af65635da08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/MyDrive/AWS/tokenizer.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "V31nOwp-oe1-",
        "VLWsZa_CogrR",
        "xOCDcSt4oV0I",
        "-NuRNioKodsQ",
        "Wh4JMpk_opQl",
        "c3bAySDFos74",
        "lo2K-pfzPSOo"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "8ae596bec0683f5529c105e9466d9a4787109878f932db46e009b054eb430bf4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}